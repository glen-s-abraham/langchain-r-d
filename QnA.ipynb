{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04121b92-d11c-4ea7-8f9d-42fa112f5fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from  dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10614a6f-9e99-4105-a427-12759ece6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY']=os.getenv('OPEN_API_KEY')\n",
    "openai.key= os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76dac739-a13a-4de7-aacf-000760b42da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_ai_magics extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_ai_magics\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07c47d33-5f3c-4a13-ae02-18b91cfba922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Document loader\n",
    "def load_document(file):\n",
    "    import os\n",
    "    #refactor to a factory\n",
    "    name,extension = os.path.splitext(file)\n",
    "    print(f'loading {file}')\n",
    "    if extension=='.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension=='.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print('Document format not supported')    \n",
    "    data=loader.load()\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74255f81-2a1f-4424-ab53-10a5d763462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Wikipedia loader\n",
    "def load_from_wikipedia(query,lang='en',load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query,lang=lang,load_max_docs=load_max_docs)\n",
    "    data=loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09146a6e-4d7c-4e47-9d23-baad8f5dd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Split document into chunks of specified size\n",
    "def chunk_data(data,chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eaa3c5a6-c6f7-488d-800b-5070d0e6ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(encoding.encode(page.page_content))\n",
    "                       for page in texts])\n",
    "    print(f'Total tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000*0.0004:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22cb1efa-bdb5-4b5f-b14c-4878e4413c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Embed data to pinecone.returns index if already embedded\n",
    "def insert_or_get_embeddings(index_name,chunks):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_KEY'),environment=os.environ.get('PINECONE_ENV'))\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    embedding= OpenAIEmbeddings()\n",
    "    if index_name in pinecone.list_indexes():\n",
    "        vector_store = Pinecone.from_existing_index(index_name=index_name,embedding=embedding)\n",
    "        print(f'{index_name} already exists. Loading embeddings')\n",
    "    else:\n",
    "        print(f'Creating index: {index_name} and embeddings',end='')\n",
    "        pinecone.create_index(index_name,dimension=1536,metric='cosine')\n",
    "        vector_store=Pinecone.from_documents(chunks,embedding=embedding,index_name=index_name)\n",
    "        print('OK')\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61ba7452-0916-4910-8d53-c6f1d2c53df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_KEY'),environment=os.environ.get('PINECONE_ENV'))\n",
    "    if(index_name=='all'):\n",
    "        indexes=pinecone.list_indexes()\n",
    "        print('Deleting all indexes.')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('OK')\n",
    "        return\n",
    "    print(f'Deleting index:{index_name}')\n",
    "    pinecone.delete_index(index)\n",
    "    print('OK')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f69af8ca-7b27-4cee-ae26-5ad6cb23eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files/2021_1656420953953.pdf\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/2021_1656420953953.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb80e0b7-8533-42a4-88dd-ea5d7efa6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_data = chunk_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "db5807b0-39f0-4c1d-b9c4-b458d1adfe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 181847\n",
      "Embedding Cost in USD: 0.072739\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b4fb29b-6d84-4097-a40e-43e44ca09ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes.\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00d6e230-29f8-4814-b421-8e339af3e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index: pvranalytics and embeddingsOK\n"
     ]
    }
   ],
   "source": [
    "index_name = 'pvranalytics'\n",
    "vector_store = insert_or_get_embeddings(index_name=index_name,chunks=chunked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f575bead-3ad7-4912-8d91-b37e322343c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_vector(question,vector_store):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    gpt = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n",
    "    vector_retriever = vector_store.as_retriever(search_type='similarity',search_kwargs={'k':3})\n",
    "    chain = RetrievalQA.from_chain_type(llm=gpt,chain_type=\"stuff\",retriever=vector_retriever)\n",
    "    answer = chain.run(question)\n",
    "    return answer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6cee78e0-24e8-4466-9173-5ab8d1475086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_vector_and_persist(question,vector_store,history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    gpt = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=1)\n",
    "    vector_retriever = vector_store.as_retriever(search_type='similarity',search_kwargs={'k':3})\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm=gpt,retriever=vector_retriever)\n",
    "    result = chain({'question':question,'chat_history':history})\n",
    "    history.append((question,result['answer']))\n",
    "    return result,history;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a71d9a76-cf65-4142-94f7-598892c3731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write quite or Exit to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 1: What are the main revenue streams of pvr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The main revenue streams of PVR include box office revenues, food and beverage sales, advertisement revenue, convenience fees, income from movie production/distribution, and interest received.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 2: can i get the revenue streams from each sources of revenue in a json format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I don't have access to the specific revenue streams from each source of revenue in a JSON format.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 3: can i get the revenue streams from each sources of revenue streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I don't have access to specific information about the revenue streams from each source.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 4: can i get the revenue streams from each sources of icome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I don't have access to specific financial information for the company. It would be best to refer to the company's financial statements or annual reports for detailed information on the revenue streams from each source of income.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 5: are there financial data in the uploaded document\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given context, it is mentioned that the document includes standalone financial statements and provides required information and documents. Therefore, it is likely that there are financial data in the uploaded document.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 6: can you extract the key strenghts of the company\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given context, the key strengths of the company can be identified as follows:\n",
      "\n",
      "1. Combined balance sheet strength: The company has a strong financial position, which can be leveraged to expand into Tier 2 and Tier 3 markets.\n",
      "\n",
      "2. Cost and revenue synergies: The company has the potential to realize significant cost savings and revenue growth by combining its resources and operations.\n",
      "\n",
      "3. Diversified stakeholders: The company has a wide range of stakeholders, including developers, content producers, technology service providers, the state exchequer, and employees. This diverse network of stakeholders can provide various benefits and opportunities for the company.\n",
      "\n",
      "4. Fair value assessment: The company uses a discounted cash flow approach to determine the fair values of its businesses. This indicates a reliable and thorough evaluation of its assets and investments.\n",
      "\n",
      "5. Focus on efficiency: The company collaborates with third parties to identify inefficiencies and improve its operations. This demonstrates a proactive approach to enhancing productivity and reducing costs.\n",
      "\n",
      "Please note that these strengths are inferred from the given context and may not encompass all the strengths of the company.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 7: what are the future plans of the company\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I don't have access to specific information about the future plans of the company. It would be best to reach out to the company directly for more information on their future plans.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 8: from the standalone financials in the documents please extract the key ratios\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I'm sorry, but I cannot access or extract specific information from documents. I can only provide general information and answer questions based on the context you provide.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 9: Is the company financially sound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the given context, it can be inferred that the company has adequate internal financial controls in place for both standalone and consolidated financial statements. However, the information provided does not directly indicate whether the company is financially sound. Additional information would be needed to determine the financial soundness of the company, such as its profitability, liquidity, and solvency.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Queation 10: quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exitng\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i=1\n",
    "print('Write quite or Exit to quit.')\n",
    "while True:\n",
    "    q=input(f'Queation {i}:')\n",
    "    i=i+1\n",
    "    if q.lower() in ['quit','exit']:\n",
    "        print('Exitng')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    answer = prompt_vector(q,vector_store)\n",
    "    print(f'Answer: {answer}')\n",
    "    print(f'\\n{\"-\"*50}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e76608e2-7b0e-4042-bec7-c39feb82cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]\n",
    "question = 'What is the document'\n",
    "result,chat_history=prompt_vector_and_persist(question,vector_store,chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10b72fea-c15d-4715-9a08-f9fca275e952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the document',\n",
       "  'The document referred to is not specified in the provided context.')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
