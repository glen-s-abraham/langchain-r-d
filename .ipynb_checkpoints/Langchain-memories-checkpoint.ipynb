{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b95ba35-a9d1-4990-89da-850b9b9171a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9230f78-af8b-45ba-8731-244fd22c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3681443d-1621-48e3-b779-444147f2ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a335965b-5bdc-456e-9939-7ed9c754f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi my name is glen\")\n",
    "conversation.predict(input=\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc11603-a650-43d0-af21-8433448e6661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Glen.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a6660e-8d6f-4221-87a6-8914c4f68357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: What is 1+1\\nAI: 1+1 is equal to 2.\\nHuman: What is my name\\nAI: I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\\nHuman: Hi my name is glen\\nAI: Hello Glen! How can I assist you today?\\nHuman: What is 1+1\\nAI: 1+1 is equal to 2.\\nHuman: What is my name\\nAI: Your name is Glen.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330759bb-8bad-46f9-9064-2da9ea678a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0)\n",
    "memory = ConversationBufferWindowMemory(k=1)#a windows of previous messages to remember can be specified.here k=1 specifies only one message needds to be remembered.\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4970d34-c437-47f7-a60f-c22d7a37daea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi my name is glen\")\n",
    "conversation.predict(input=\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb1dddb-1cdc-4fd1-a8f5-40f12ec1626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3f73f5b-adca-480c-bd44-2702f3b0699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0)\n",
    "memory = ConversationTokenBufferMemory(llm=llm,max_token_limit=100)#a windows of previous messages to remember can be specified.here k=1 specifies only one message needds to be remembered.\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a976503d-7b4c-484f-9508-e3c62676503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi my name is glen\")\n",
    "conversation.predict(input=\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f65d1b7-a1ef-442c-9a6a-2ac532dcbf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Glen.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9069557-364d-43ac-aa6c-e4dcca4003e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm)#a windows of previous messages to remember can be specified.here k=1 specifies only one message needds to be remembered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "442bee38-1460-4778-8a25-da468c8d9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "990755b8-4e08-4df7-ad5d-b11e8fa78972",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbef971c-b8d4-4589-b180-1d7a8171e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"There are many great demos that you could consider showing depending on your interests and the context. If you're into technology, you could showcase a virtual reality experience or a cool new app. If you're more into art, you could display a painting or a sculpture. If you're interested in science, you could demonstrate a simple experiment or a model. Ultimately, the best demo to show would be something that aligns with your passions and captivates your audience.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b05c12-0b95-4cdf-8a20-e33022cde6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: What would be a good demo to show?\\nAI: There are many great demos that you could consider showing depending on your interests and the context. If you're into technology, you could showcase a virtual reality experience or a cool new app. If you're more into art, you could display a painting or a sculpture. If you're interested in science, you could demonstrate a simple experiment or a model. Ultimately, the best demo to show would be something that aligns with your passions and captivates your audience.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b730e-182e-4437-b791-6e4c27d7d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import MongoDBChatMessageHistory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
